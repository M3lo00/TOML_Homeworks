{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(\"BC-Data-Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime object\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Remove any missing values\n",
    "data = data.dropna()\n",
    "\n",
    "data = data.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not filled\n",
      "not filled\n",
      "not filled\n",
      "not filled\n",
      "not filled\n",
      "not filled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/vjzgtvsn0dv9v9r8s48fg1t00000gn/T/ipykernel_14553/2192792224.py:5: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for group_name, group_data in test:\n"
     ]
    }
   ],
   "source": [
    "#here we fill only the days where less than 3 consecutive missing values are present\n",
    "\n",
    "mean_values=data.mean()\n",
    "test= data.groupby([data.index.date])\n",
    "for group_name, group_data in test:\n",
    "    if (len(group_data)<24 and len(group_data)>17):\n",
    "        existing_hours=group_data.index.hour.unique()\n",
    "        missing_hours = set(range(24)) - set(existing_hours)\n",
    "        missing_rows = pd.DataFrame(columns=group_data.columns)\n",
    "        for missing_hour in missing_hours:\n",
    "            datetime_obj = pd.to_datetime(group_data.index.date[0]) + pd.to_timedelta(missing_hour, unit='H')\n",
    "            \n",
    "            if(datetime_obj + pd.Timedelta(hours=1) in data.index) and (datetime_obj - pd.Timedelta(hours=1) in data.index):\n",
    "                 data.loc[datetime_obj] = (data.loc[datetime_obj-pd.Timedelta(hours=1)] + data.loc[datetime_obj+pd.Timedelta(hours=1)]) / 2\n",
    "                 \n",
    "            elif (datetime_obj - pd.Timedelta(hours=1) in data.index):\n",
    "                data.loc[datetime_obj] = (data.mean() + data.loc[datetime_obj-pd.Timedelta(hours=1)]) / 2\n",
    "            else:\n",
    "                print(\"not filled\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01    24\n",
      "2019-01-02    24\n",
      "2019-01-03    24\n",
      "2019-01-04    24\n",
      "2019-01-08    24\n",
      "              ..\n",
      "2019-12-02    24\n",
      "2019-12-03    24\n",
      "2019-12-04    13\n",
      "2019-12-09    24\n",
      "2019-12-10    24\n",
      "Length: 191, dtype: int64\n",
      "Index([2019-01-23, 2019-01-24, 2019-02-02, 2019-02-08, 2019-02-10, 2019-02-25,\n",
      "       2019-02-26, 2019-02-27, 2019-02-28, 2019-03-10, 2019-04-03, 2019-05-01,\n",
      "       2019-07-01, 2019-07-02, 2019-07-03, 2019-07-10, 2019-07-23, 2019-07-27,\n",
      "       2019-08-02, 2019-08-04, 2019-08-10, 2019-08-22, 2019-09-04, 2019-10-15,\n",
      "       2019-10-16, 2019-12-04],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique hours for each date\n",
    "hours_per_day = data.groupby(data.index.date).size()\n",
    "\n",
    "print(hours_per_day)\n",
    "\n",
    "# Get the dates that have less than 24 unique hours\n",
    "incomplete_days = hours_per_day[hours_per_day < 24].index\n",
    "\n",
    "print(incomplete_days)\n",
    "\n",
    "# Convert the incomplete_days array to a DatetimeIndex\n",
    "date_index = pd.DatetimeIndex(data.index.date)\n",
    "\n",
    "# Filter the DataFrame to exclude the rows corresponding to incomplete days\n",
    "data_complete_days = data[~date_index.isin(incomplete_days)]\n",
    "\n",
    "data_incomplete_days = data[date_index.isin(incomplete_days)]\n",
    "\n",
    "data_complete_days.to_csv(\"semi_filled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sort_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"filled_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = data.corr()\n",
    "bc_correlations = correlations['BC']\n",
    "print(bc_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots\n",
    "sns.pairplot(data, x_vars=data.columns[1:], y_vars=['BC'])\n",
    "\n",
    "# Heat map\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(correlations, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series data\n",
    "data.plot(subplots=True, figsize=(12, 16))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold = 5 # theshold a little high to retain some outliers\n",
    "z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))\n",
    "outliers = (z_scores > threshold).any(axis=1)\n",
    "for column in data.columns:\n",
    "    column_mean = data[column].mean()\n",
    "    data.loc[outliers, column] = column_mean\n",
    "data.plot(subplots=True, figsize=(12, 16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily averages\n",
    "daily_data = data.resample('D').mean()\n",
    "\n",
    "# Weekly averages\n",
    "weekly_data = data.resample('W').mean()\n",
    "\n",
    "# Visualize the daily and weekly trends using line charts\n",
    "daily_data.plot(subplots=True, figsize=(12, 16), title='Daily Averages')\n",
    "weekly_data.plot(subplots=True, figsize=(12, 16), title='Weekly Averages')\n",
    "\n",
    "# Visualize the daily and weekly trends using box plots\n",
    "daily_data.boxplot(figsize=(12, 7))\n",
    "plt.title('Daily Averages')\n",
    "weekly_data.boxplot(figsize=(12, 7))\n",
    "plt.title('Weekly Averages')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_dataframe(df, columns):\n",
    "    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17,17))\n",
    "    for i, col in enumerate(columns):\n",
    "        axs[i].plot(df[col])\n",
    "        axs[i].set_title(col)\n",
    "    plt.show()\n",
    "inspect_dataframe(data, data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 24*25\n",
    "\n",
    "X_train_raw = data.iloc[:-test_size]\n",
    "# y_train_raw = y.iloc[:-test_size]\n",
    "X_test_raw = data.iloc[-test_size:]\n",
    "# y_test_raw = y.iloc[-test_size:]\n",
    "print(X_train_raw.shape, X_test_raw.shape)\n",
    "\n",
    "# Normalize both features and labels\n",
    "X_min = X_train_raw.min()\n",
    "X_max = X_train_raw.max()\n",
    "\n",
    "X_train_raw = (X_train_raw-X_min)/(X_max-X_min)\n",
    "X_test_raw = (X_test_raw-X_min)/(X_max-X_min)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(X_train_raw.BC, label='Train (temperature)')\n",
    "plt.plot(X_test_raw.BC, label='Test (temperature)')\n",
    "plt.title('Train-Test Split')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(X_test_raw.BC, label='Test (temperature)')\n",
    "plt.title('Train-Test Split')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TOML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # Report only TF errors by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.config.set_visible_devices([], 'GPU') #disables GPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(\"BC-Data-Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime object\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Remove any missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Set the date column as the index of the DataFrame\n",
    "data = data.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, data.BC, test_size=0.15, random_state=seed, shuffle=True)\n",
    "x_train = x_train.drop(columns=['BC'])\n",
    "x_test = x_test.drop(columns=['BC'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split, preprocess, make sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum() # check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 300\n",
    "X_train_raw = data.iloc[:-test_size]\n",
    "# y_train_raw = y.iloc[:-test_size]\n",
    "X_test_raw = data.iloc[-test_size:]\n",
    "# y_test_raw = y.iloc[-test_size:]\n",
    "print(X_train_raw.shape, X_test_raw.shape)\n",
    "\n",
    "# Normalize both features and labels\n",
    "X_min = X_train_raw.min()\n",
    "X_max = X_train_raw.max()\n",
    "\n",
    "X_train_raw = (X_train_raw-X_min)/(X_max-X_min)\n",
    "X_test_raw = (X_test_raw-X_min)/(X_max-X_min)\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.plot(X_train_raw.BC, label='Train (BC)')\n",
    "plt.plot(X_test_raw.BC, label='Test (BC)')\n",
    "plt.title('Train-Test Split')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (non-LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 512\n",
    "inputs = tf.keras.layers.Input(shape=[x_train.shape[-1]])\n",
    "\n",
    "layer = keras.layers.Dense(HIDDEN_DIM, activation='relu')(inputs)\n",
    "layer = keras.layers.Dropout(0.4)(layer)\n",
    "layer = keras.layers.Dense(HIDDEN_DIM//2, activation='relu')(layer)\n",
    "layer = keras.layers.Dropout(0.4)(layer)\n",
    "layer = keras.layers.Dense(HIDDEN_DIM//3, activation='relu')(layer)\n",
    "layer = keras.layers.Dropout(0.4)(layer)\n",
    "predictions = keras.layers.Dense(1, activation='linear')(layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "            loss=tf.losses.mean_squared_error,\n",
    "            metrics=[tf.metrics.mean_squared_error],\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2000\n",
    "logs = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size, epochs=epochs,\n",
    "    validation_split=.1,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50,  restore_best_weights=True)\n",
    "                            ],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 12\n",
    "stride = 12\n",
    "target_labels = 'BC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_sequences(df, target_labels=['BC'], window=200, stride=200):\n",
    "    # Sanity check to avoid runtime errors\n",
    "    assert window % stride == 0\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    temp_df = df.copy().values\n",
    "    temp_label = df[target_labels].copy().values\n",
    "    padding_len = len(df) % window\n",
    "    \n",
    "    if padding_len != 0:\n",
    "        # Compute padding length\n",
    "        padding_len = window - len(df) % window\n",
    "        padding = np.zeros((padding_len, temp_df.shape[1]), dtype='float32')\n",
    "        temp_df = np.concatenate((padding, temp_df))\n",
    "        padding = np.zeros((padding_len,), dtype='float32')\n",
    "        #padding = np.zeros((padding_len, temp_label.shape[1]), dtype='float32')\n",
    "        temp_label = np.concatenate((padding, temp_label))\n",
    "        assert len(temp_df) % window == 0\n",
    "\n",
    "    # Build sequences and labels\n",
    "    for i in range(0, len(temp_df) - window + 1, stride):\n",
    "        dataset.append(temp_df[i:i + window])\n",
    "        labels.append(temp_label[i:i + window])\n",
    "\n",
    "    return np.array(dataset), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = build_sequences(data, target_labels, window, stride)\n",
    "X_test, y_test = build_sequences(data, target_labels, window, stride)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def inspect_multivariate(X, y, columns, telescope, idx=None):\n",
    "    if(idx==None):\n",
    "        idx=np.random.randint(0,len(X))\n",
    "\n",
    "    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17,17))\n",
    "    for i, col in enumerate(columns):\n",
    "        axs[i].plot(np.arange(len(X[0,:,i])), X[idx,:,i])\n",
    "        axs[i].scatter(np.arange(len(X[0,:,i]), len(X_train[0,:,i])+telescope), y[idx,:,i], color='orange')\n",
    "        axs[i].set_title(col)\n",
    "        axs[i].set_ylim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspect_multivariate(X_train, y_train, target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "output_shape = y_train.shape[1:]\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CONV_LSTM_model(input_shape, output_shape):\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tf.keras.layers.Input(shape=input_shape, name='input_layer')\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, name='lstm'), name='bidirectional_lstm')(input_layer)\n",
    "    x = tf.keras.layers.Conv1D(128, 3, padding='same', activation='relu', name='conv')(x)\n",
    "    if output_shape[0] == 1:\n",
    "        output_layer = tf.keras.layers.Conv1D(output_shape[1], 3, padding='same', activation='sigmoid', name='output_layer')(x)\n",
    "        output_layer = tf.keras.layers.GlobalAveragePooling1D(keepdims=True, name='gap')(output_layer)\n",
    "    else:\n",
    "        output_layer = tf.keras.layers.Conv1D(1, 3, padding='same', activation='sigmoid', name='output_layer')(x)\n",
    "        crop_size = (1-output_shape[0])//2\n",
    "        output_layer = tf.keras.layers.Cropping1D((crop_size,crop_size), name='cropping')(output_layer)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.legacy.Adam(), metrics=['mae'])\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_CONV_LSTM_model(input_shape, output_shape)\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x = X_train,\n",
    "    y = y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_split=.1,\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.1, min_lr=1e-5)\n",
    "    ]\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_split=.1,\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.1, min_lr=1e-5)\n",
    "    ]\n",
    ").history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 12\n",
    "SEQUENCE_DIM = x_train.shape[-1]\n",
    "RNN_CELL_DIM = 8\n",
    "HIDDEN_DIM = 8\n",
    "sequences = tf.keras.layers.Input(shape=[SEQUENCE_LENGTH, SEQUENCE_DIM])\n",
    "\n",
    "layer = keras.layers.LSTM(RNN_CELL_DIM, return_sequences=True)(sequences)\n",
    "\n",
    "layer = keras.layers.Dense(HIDDEN_DIM, activation='relu')(layer)\n",
    "\n",
    "predictions = keras.layers.Dense(1, activation=None)(layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=sequences, outputs=predictions)\n",
    "model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "            loss=tf.losses.mean_squared_error,\n",
    "            metrics=[tf.metrics.mean_squared_error],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

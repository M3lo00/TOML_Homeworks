{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # Report only TF errors by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melo/miniconda3/envs/my_tf_env/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(\"BC-Data-Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to a datetime object\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Remove any missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Set the date column as the index of the DataFrame\n",
    "data = data.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, data.BC, test_size=0.15, random_state=seed, shuffle=True)\n",
    "x_train = x_train.drop(columns=['BC'])\n",
    "x_test = x_test.drop(columns=['BC'])\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15, random_state=seed, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split, preprocess, make sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.73291434,  1.55477006,  3.60894021, ...,  1.95560752,\n",
       "        -0.89521109,  0.69813568],\n",
       "       [-0.85503739, -0.08410553, -0.35847915, ..., -0.37050872,\n",
       "        -0.48279646,  0.2517087 ],\n",
       "       [-0.38903519, -0.40824082, -0.54120237, ...,  0.15400768,\n",
       "        -1.71157723, -1.90387708],\n",
       "       ...,\n",
       "       [-0.89772   , -0.72621189, -0.91761219, ..., -0.39331378,\n",
       "         0.94389125, -0.81840302],\n",
       "       [-0.48238073,  0.10302261, -0.19784883, ...,  1.11182025,\n",
       "         1.35890992, -0.49238002],\n",
       "       [-0.7281987 , -0.953701  , -1.27475302, ..., -0.48453403,\n",
       "        -1.55972922, -2.74749276]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3050, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (non-LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 128\n",
    "inputs = tf.keras.layers.Input(shape=[x_train.shape[-1]])\n",
    "\n",
    "layer = keras.layers.Dense(HIDDEN_DIM, activation='relu')(inputs)\n",
    "layer = keras.layers.Dense(HIDDEN_DIM, activation='relu')(layer)\n",
    "\n",
    "predictions = keras.layers.Dense(1, activation=None)(layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "            loss=tf.losses.mean_squared_error,\n",
    "            metrics=[tf.metrics.mean_squared_error],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.7723 - mean_squared_error: 0.7723 - val_loss: 0.5040 - val_mean_squared_error: 0.5040\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.4109 - mean_squared_error: 0.4109 - val_loss: 0.4348 - val_mean_squared_error: 0.4348\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.3572 - mean_squared_error: 0.3572 - val_loss: 0.3953 - val_mean_squared_error: 0.3953\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.3206 - mean_squared_error: 0.3206 - val_loss: 0.3873 - val_mean_squared_error: 0.3873\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2991 - mean_squared_error: 0.2991 - val_loss: 0.3539 - val_mean_squared_error: 0.3539\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.2800 - mean_squared_error: 0.2800 - val_loss: 0.3523 - val_mean_squared_error: 0.3523\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.2758 - mean_squared_error: 0.2758 - val_loss: 0.3223 - val_mean_squared_error: 0.3223\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2582 - mean_squared_error: 0.2582 - val_loss: 0.3297 - val_mean_squared_error: 0.3297\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2535 - mean_squared_error: 0.2535 - val_loss: 0.3184 - val_mean_squared_error: 0.3184\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2453 - mean_squared_error: 0.2453 - val_loss: 0.3307 - val_mean_squared_error: 0.3307\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2342 - mean_squared_error: 0.2342 - val_loss: 0.3420 - val_mean_squared_error: 0.3420\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.2481 - mean_squared_error: 0.2481 - val_loss: 0.3330 - val_mean_squared_error: 0.3330\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2288 - mean_squared_error: 0.2288 - val_loss: 0.3979 - val_mean_squared_error: 0.3979\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2224 - mean_squared_error: 0.2224 - val_loss: 0.3153 - val_mean_squared_error: 0.3153\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2196 - mean_squared_error: 0.2196 - val_loss: 0.2971 - val_mean_squared_error: 0.2971\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2000 - mean_squared_error: 0.2000 - val_loss: 0.3225 - val_mean_squared_error: 0.3225\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2059 - mean_squared_error: 0.2059 - val_loss: 0.2981 - val_mean_squared_error: 0.2981\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1894 - mean_squared_error: 0.1894 - val_loss: 0.2951 - val_mean_squared_error: 0.2951\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1803 - mean_squared_error: 0.1803 - val_loss: 0.2962 - val_mean_squared_error: 0.2962\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1819 - mean_squared_error: 0.1819 - val_loss: 0.3321 - val_mean_squared_error: 0.3321\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "logs = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size, epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    # callbacks=[model.tb_callback],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def build_sequences(df, window=200, stride=200):\n",
    "    # Sanity check to avoid runtime errors\n",
    "    assert window % stride == 0\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for id in df['id'].unique():\n",
    "        # Take only meaningful features\n",
    "        temp = df[df['id'] == id][['x_axis','y_axis','z_axis']].values\n",
    "        # Save the label\n",
    "        label = df[df['id'] == id]['activity'].values[0]\n",
    "        print(str(id), \"  \", str(label))\n",
    "        # Compute padding length\n",
    "        padding_len = window - len(temp)%window\n",
    "        # Create padding and concatenate it\n",
    "        padding = np.zeros((padding_len,3), dtype='float64')\n",
    "        temp = np.concatenate((temp,padding))\n",
    "        # Build features windows with their corresponging labels\n",
    "        idx = 0\n",
    "        while idx+window <= len(temp):\n",
    "            dataset.append(temp[idx:idx+window])\n",
    "            labels.append(label)\n",
    "            idx += stride\n",
    "    dataset = np.array(dataset)\n",
    "    labels = np.array(labels)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 8\n",
    "SEQUENCE_DIM = x_train.shape[-1]\n",
    "RNN_CELL_DIM = 8\n",
    "HIDDEN_DIM = 8\n",
    "sequences = tf.keras.layers.Input(shape=[SEQUENCE_LENGTH, SEQUENCE_DIM])\n",
    "\n",
    "layer = keras.layers.LSTM(RNN_CELL_DIM, return_sequences=True)(sequences)\n",
    "\n",
    "layer = keras.layers.Dense(HIDDEN_DIM, activation='relu')(layer)\n",
    "\n",
    "predictions = keras.layers.Dense(1, activation=None)(layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=sequences, outputs=predictions)\n",
    "model.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss=tf.losses.mean_squared_error,\n",
    "            metrics=[tf.metrics.mean_squared_error],\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
